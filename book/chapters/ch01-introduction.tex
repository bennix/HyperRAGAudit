\chapter{导论：为什么需要 RAG 审计系统}
\label{ch:introduction}

\section{大语言模型的局限性}

大语言模型（Large Language Model, LLM）\index{LLM}在自然语言理解和生成方面展示了惊人的能力，但它们存在几个固有局限：

\begin{enumerate}[label=(\arabic*)]
  \item \textbf{知识截止日期}：模型的知识停留在训练数据的截止时间，无法获取最新信息。
  \item \textbf{幻觉问题}：LLM 可能生成听起来合理但事实上不正确的内容，在审计场景中这是不可接受的。
  \item \textbf{无法访问私有数据}：企业内部的合同、发票、财务报表等文档不在公开训练数据中。
  \item \textbf{缺乏可溯源性}：LLM 的输出无法直接追溯到源文档的具体位置。
\end{enumerate}

这些局限性在企业审计场景中尤为突出——审计员需要的是\textbf{有据可查、可溯源}的结论，而不是模型的"自由发挥"。

\section{什么是 RAG}

RAG（Retrieval-Augmented Generation，检索增强生成）\index{RAG}是一种将信息检索与文本生成相结合的架构模式。其核心思想非常简洁：

\begin{notebox}[RAG 核心思想]
不要让模型凭记忆回答，而是先从知识库中检索相关文档，然后让模型基于检索到的内容生成回答。
\end{notebox}

一个标准的 RAG 流程包含以下步骤：

\begin{enumerate}[label=\textbf{Step \arabic*}:]
  \item \textbf{文档解析}——将 PDF、图片、Word 等文档转换为结构化文本。
  \item \textbf{向量化索引}——将文本切分为语义块，通过嵌入模型（Embedding Model）转换为向量，存入向量数据库。
  \item \textbf{检索}——用户提问时，将问题向量化，在向量数据库中搜索语义最相近的文档块。
  \item \textbf{生成}——将检索到的文档块作为上下文，连同用户问题一起发送给 LLM，生成回答。
\end{enumerate}

\section{从基础 RAG 到 HyperRAG}

基础 RAG 系统虽然解决了 LLM 无法访问私有数据的问题，但在企业审计场景中仍有不足：

\begin{table}[htbp]
\centering
\caption{基础 RAG 与 HyperRAG 的对比}
\label{tab:rag-comparison}
\begin{tabular}{lll}
\toprule
\textbf{维度} & \textbf{基础 RAG} & \textbf{HyperRAG} \\
\midrule
文档解析 & 纯文本提取 & Vision LLM + BBox 坐标 \\
检索方式 & 仅向量语义搜索 & 向量搜索 + 知识图谱 \\
推理能力 & 单轮问答 & ReAct Agent 多步推理 \\
溯源能力 & 返回文本片段 & PDF 原文高亮定位 \\
实体关系 & 无 & 自动构建知识图谱 \\
\bottomrule
\end{tabular}
\end{table}

HyperRAG 在基础 RAG 之上引入了四个关键增强：

\begin{description}
  \item[Vision OCR + 坐标提取] 使用 Vision LLM 对文档页面进行 OCR，同时提取每个内容块的边界框坐标（Bounding Box），实现从解析结果到原始文档的精确映射。
  \item[知识图谱] 自动从文档中提取实体（人物、公司、金额、日期等）及其关系，构建知识图谱，支持关系推理和路径查询。
  \item[ReAct Agent] 基于 LangGraph 构建的 ReAct 模式 Agent，配备 5 个专用工具，能够多步推理、交叉验证，产出结构化审计报告。
  \item[PDF 溯源高亮] 将 Vision LLM 返回的归一化坐标转换为 PDF 物理坐标，在原始 PDF 上高亮标注审计发现的证据来源。
\end{description}

\section{本书的读者对象}

本书面向以下读者：

\begin{itemize}
  \item 希望了解 RAG 系统完整架构的开发者
  \item 想要构建文档智能分析系统的工程师
  \item 对 LLM Agent、知识图谱感兴趣的技术人员
  \item 有 Python 基础，希望深入理解 LangChain/LangGraph 的学习者
\end{itemize}

\begin{tipbox}[前置知识]
阅读本书需要以下基础知识：
\begin{itemize}
  \item Python 3.10+ 基础语法
  \item 了解 HTTP API 基本概念（请求、响应、JSON）
  \item 对大语言模型有基本认知（知道什么是 ChatGPT/Claude）
\end{itemize}
\end{tipbox}

\section{本书结构}

本书共 10 章，按照系统构建的自然顺序组织：

\begin{description}
  \item[第 1 章] 导论——介绍 RAG 概念与 HyperRAG 的定位（本章）。
  \item[第 2 章] 系统架构——总览系统设计、技术选型与数据流。
  \item[第 3 章] 文档处理——PDF/图片/Word 文件的转换与预处理。
  \item[第 4 章] Vision OCR——使用 Vision LLM 实现带坐标的内容提取。
  \item[第 5 章] 向量数据库——ChromaDB 索引与语义检索。
  \item[第 6 章] 知识图谱——实体抽取、关系提取与 NetworkX 图存储。
  \item[第 7 章] 审计 Agent——LangGraph ReAct Agent 与工具设计。
  \item[第 8 章] PDF 溯源高亮——坐标转换与 PyMuPDF 标注。
  \item[第 9 章] Web 界面——Streamlit 应用与交互设计。
  \item[第 10 章] 配置与部署——系统配置、API 网关与生产部署。
\end{description}

\section{LLM API：ZenMux 统一网关}
\label{sec:zenmux-intro}

HyperRAG 的所有 LLM 调用都通过 ZenMux\index{ZenMux} 统一 API 网关完成。ZenMux 提供 OpenAI 兼容的 API 接口，一个 Key 即可调用 200+ 模型（GPT、Claude、Gemini、Llama 等）。

注册地址：\url{https://zenmux.ai/invite/GBQMC5}

使用 ZenMux 的优势：
\begin{itemize}
  \item \textbf{统一接口}——所有模型都使用 \texttt{/v1/chat/completions} 格式调用，无需为不同供应商维护不同的 SDK。
  \item \textbf{灵活切换}——只需修改 \texttt{config.yaml} 中的模型名称即可切换供应商（如从 GPT 切到 Claude）。
  \item \textbf{负载均衡}——内置故障转移和负载均衡，提升服务稳定性。
\end{itemize}

\begin{lstlisting}[language=yaml,caption={config.yaml 中的 API 配置}]
api:
  base_url: "https://zenmux.ai/api/v1"
  api_key: "sk-your-api-key"
models:
  ocr_model: "openai/gpt-5.2-chat"
  agent_model: "anthropic/claude-sonnet-4"
\end{lstlisting}
